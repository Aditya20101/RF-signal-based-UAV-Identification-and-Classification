{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root,dirs,files) in os.walk('E:/minor_3_dataset/Clean/'):\n",
    "    print()\n",
    "\n",
    "print(files)\n",
    "path=\"\"\n",
    "# Second method to  load hdf5 file in case of error\n",
    "# df1 = pd.DataFrame(np.array(h5py.File(path)['air']))\n",
    "X = pd.read_hdf(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.20, random_state=0)\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Normalizing data for numerical stability\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss_train = StandardScaler()\n",
    "X_train = ss_train.fit_transform(X_train)\n",
    "\n",
    "ss_test = StandardScaler()\n",
    "X_test = ss_test.fit_transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "history = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression(max_iter=3000)\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    # Fit the classifier\n",
    "    models[key].fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = models[key].predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy[key] = accuracy_score(predictions, y_test)\n",
    "    precision[key] = precision_score(predictions, y_test,average='micro')\n",
    "    recall[key] = recall_score(predictions, y_test,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_model.plot.barh()\n",
    "ax.legend(\n",
    "    ncol=len(models.keys()), \n",
    "    bbox_to_anchor=(0, 1), \n",
    "    loc='lower left', \n",
    "    prop={'size': 14}\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.layers import LSTM,Dropout,Dense,TimeDistributed,Conv1D,MaxPooling1D,InputLayer,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = 28800, 6000, 18 \n",
    "# Rows,      Columns,    Output classes\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_outputs)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_outputs)\n",
    "\n",
    "number_epoch = 25\n",
    "batch_length = 16\n",
    "inp_shape=(6000,)\n",
    "inner_activation_fun = 'relu'\n",
    "outer_activation_fun = 'softmax'\n",
    "optimizer_loss_fun = 'categorical_crossentropy'\n",
    "optimizer_algorithm = 'adam'\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape = inp_shape),\n",
    "        Flatten(),\n",
    "        Dense(256,activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(256,activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(256,activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(256,activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(n_outputs,activation = \"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\" , metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tme = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=number_epoch, batch_size=batch_length, validation_data=(X_test, y_test))\n",
    "end_time = time.time()\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test,y_test,verbose = 0)\n",
    "print(\"Test loss : \", score[0])\n",
    "print(\"Test Accuracy : \", score[1])\n",
    "print(\"Training Time : \",end_time - start_tme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "ytest = np.argmax(y_test,axis=1)\n",
    "pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest,pred))\n",
    "cm = confusion_matrix(ytest,pred)\n",
    "plot= ConfusionMatrixDisplay(cm)\n",
    "plot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_inner_layers = 5\n",
    "number_inner_neurons = 2048\n",
    "show_inter_results = 0\n",
    "\n",
    "model = Sequential()\n",
    "for i in range(number_inner_layers):\n",
    "    number_inner_neurons=number_inner_neurons/2\n",
    "    model.add(Dense(int(number_inner_neurons), input_dim=inp_shape, activation=inner_activation_fun))\n",
    "    model.add(Dropout(0.3))\n",
    "model.add(Dense(n_outputs, activation=outer_activation_fun))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=optimizer_loss_fun, optimizer=optimizer_algorithm, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "start_tme = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=number_epoch, batch_size=batch_length, validation_data=(X_test, y_test))\n",
    "end_time = time.time()\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "score = model.evaluate(X_test,y_test,verbose = 0)\n",
    "print(\"Test loss : \", score[0])\n",
    "print(\"Test Accuracy : \", score[1])\n",
    "print(\"Training Time : \",end_time - start_tme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "ytest = np.argmax(y_test,axis=1)\n",
    "pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest,pred))\n",
    "cm = confusion_matrix(ytest,pred)\n",
    "plot= ConfusionMatrixDisplay(cm)\n",
    "plot.plot()\n",
    "# plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del pred\n",
    "# del y_pred\n",
    "# del ytest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build a sequential model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=inp_shape))\n",
    "# 1st conv block\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "# 2nd conv block\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "# 3rd conv block\n",
    "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "# ANN block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# output layer\n",
    "model.add(Dense(units=n_outputs, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_length, epochs=number_epoch, validation_data=(X_test, y_test))\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test,y_test,verbose = 0)\n",
    "print(\"Test loss : \", score[0])\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "ytest = np.argmax(y_test,axis=1)\n",
    "pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()\n",
    "cm = confusion_matrix(ytest,pred)\n",
    "plot= ConfusionMatrixDisplay(cm)\n",
    "plot.plot()\n",
    "# plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pred\n",
    "del y_pred\n",
    "del ytest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=X_train.reshape(28800,6000,1)\n",
    "y_train=y_train.reshape(28800,18)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=inp_shape))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_length, epochs=number_epoch, validation_data=(X_test, y_test))\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test,y_test,verbose = 0)\n",
    "print(\"Test loss : \", score[0])\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()\n",
    "cm = confusion_matrix(ytest,pred)\n",
    "plot= ConfusionMatrixDisplay(cm)\n",
    "plot.plot()\n",
    "# plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM + CNN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((28800,6000, 1))\n",
    "y_train = y_train.reshape((28800,18))\n",
    "\n",
    "n_timesteps, n_features, n_outputs = 28800, 6000, 18\n",
    "inp_shape = (n_features,1)\n",
    "model = Sequential(name='DC')\n",
    "\n",
    "# LFLB1\n",
    "model.add(Conv1D(filters = 256,kernel_size = (3),strides=1,padding='same',data_format='channels_last',input_shape=inp_shape))\t\n",
    "model.add(BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('elu'))\n",
    "model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\t#LFLB2\n",
    "model.add(Conv1D(filters=256, kernel_size = 3, strides=1,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('elu'))\n",
    "model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\t#LFLB3\n",
    "model.add(Conv1D(filters=256, kernel_size = 3, strides=1,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('elu'))\n",
    "model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\t#LFLB4\n",
    "model.add(Conv1D(filters=256, kernel_size = 3, strides=1,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('elu'))\n",
    "model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
    "\t#LSTM\n",
    "model.add(LSTM(units=128)) \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#FC\n",
    "model.add(Dense(units=18,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "start_tme = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=number_epoch, batch_size=batch_length, validation_data=(X_test, y_test))\n",
    "end_time = time.time()\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test,y_test,verbose = 0)\n",
    "print(\"Test loss : \", score[0])\n",
    "print(\"Test Accuracy : \", score[1])\n",
    "print(\"Training Time : \",end_time - start_tme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "ytest = np.argmax(y_test,axis=1)\n",
    "pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest,pred))\n",
    "cm = confusion_matrix(ytest,pred)\n",
    "plot= ConfusionMatrixDisplay(cm)\n",
    "plot.plot()\n",
    "# plt.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
